{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3da5bc31-3199-49b0-9911-150af0162694",
   "metadata": {},
   "source": [
    "![image](https://github.com/eWaterCycle/ewatercycle/raw/main/docs/examples/logo.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bd23205-49f5-4dde-b688-27f1217871a7",
   "metadata": {},
   "source": [
    "## This notebook accompanies the publication by Aerts et al. (review) to demonstrate how extensive model studies can be conducted using the eWaterCycle Platform."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a75b340-e204-4e40-8d38-e9558862ea34",
   "metadata": {},
   "source": [
    "## Case study 3: Parallel calibration of the KsatHorFrac Parameter of the wflow sbm hydrological model\n",
    "In this notebook we show how the KsatHorFrac Parameter can be manually calibrated for the wflow sbm model using eWaterCycle. This experiment is setup as follows: <br>\n",
    "    1. Generation of ERA5 model specific forcing.<br>\n",
    "    2. Creation of multiple model instances according to a calibration value interval.<br>\n",
    "    3. Storage of simulated streamflow output.<br>\n",
    "    4. Analysis using  USGS streamflow observation based on the KGE objective function (Gupta et al., 2009).<br>\n",
    "    5. Selection of optimal KsatHorFrac parameter value.<br>\n",
    "    6. Preperations for evaluation model run.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f31b624-c9c9-4702-a5bd-d06e051e939b",
   "metadata": {},
   "source": [
    "### Interested in using eWaterCycle, checkout the package https://ewatercycle.readthedocs.io/en/latest/ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaca847c-e76d-49ed-b4dd-8da631832846",
   "metadata": {},
   "source": [
    "## Import statements\n",
    "We'll be using the following modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5c52872-55b5-4ddf-bb51-6f24322bcb2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import shutil\n",
    "import time\n",
    "\n",
    "import geopandas as gpd\n",
    "import hvplot.xarray\n",
    "import HydroErr as he\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import xarray as xr\n",
    "\n",
    "import ewatercycle.forcing\n",
    "import ewatercycle.models\n",
    "import ewatercycle.parameter_sets\n",
    "from ewatercycle.observation.usgs import get_usgs_data\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "import logging\n",
    "import warnings\n",
    "from datetime import date\n",
    "from pathlib import Path\n",
    "\n",
    "from pathos.threading import ThreadPool as Pool\n",
    "# SWITCH TO MULTIPROCESSING STANDARD PYTHON LIB\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "\n",
    "logger = logging.getLogger(\"esmvalcore\")\n",
    "logger.setLevel(logging.WARNING)\n",
    "logging.basicConfig(level=logging.WARN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c7554a9-5232-4997-927f-967a49452391",
   "metadata": {},
   "source": [
    "# Configuration\n",
    "Here we specify the paths and basin id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b293070-4356-4463-8255-fecb248c7469",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Paths\n",
    "ROOTDIR = Path(\n",
    "    \"/gpfs/home6/jaerts/eWaterCycle_example_data/wflow_camels_parameters/\"\n",
    ")\n",
    "AUXDIR = Path(\"/gpfs/home6/jaerts/eWaterCycle_example_data/camels_input_files/\")\n",
    "OUTDIR = Path(\"/gpfs/home6/jaerts/eWaterCycle_example_data/ewatercycle_output/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "198a6ce5-871d-47ff-91da-cddd49a1e37f",
   "metadata": {},
   "source": [
    "A loop can be inserted here to run multiple basins and resolutions consecutively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3b678c3d-6fd3-4d6f-87d7-1540ced4d81c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify Catchment ID\n",
    "# Create list for running all basins\n",
    "basin_id = \"01123000\"\n",
    "\n",
    "# Specify model instance resolution\n",
    "# Create list for runnning all basins\n",
    "resolution = \"3km\"\n",
    "\n",
    "# Get basin model instance directory\n",
    "BASINDIR = Path(glob.glob(f\"{ROOTDIR}/{resolution}/*{basin_id}*/\")[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20768633-7228-4354-a015-ba1e284b739c",
   "metadata": {},
   "source": [
    "## Configure Parameter Set\n",
    "Now we load the eWaterCycle configuration file and add the parameter set information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e2f18dbc-c57f-4266-bd87-33bdc6837871",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load eWaterCycle config file\n",
    "ewatercycle.CFG.load_from_file(\"./ewatercycle.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f9dbfbf-1e63-4d08-b62c-9fa874c27e19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/gpfs/home6/jaerts/eWaterCycle_example_notebooks/ewatercycle_example_notebooks/ewatercycle.yaml')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set wflow_sbm parameter set info\n",
    "if ewatercycle.CFG[\"parameter_sets\"] is None:\n",
    "    ewatercycle.CFG[\"parameter_sets\"] = {}\n",
    "\n",
    "ewatercycle.CFG[\"parameter_sets\"][\"329_camels_06043500_3km\"] = dict(\n",
    "    directory=str(BASINDIR),\n",
    "    config=f\"{str(BASINDIR)}/wflow_sbm_calibration.ini\",\n",
    "    doi=\"N/A\",\n",
    "    target_model=\"wflow\",\n",
    "    supported_model_versions={\"2020.1.1\", \"2020.1.2\"},\n",
    ")\n",
    "\n",
    "# Save to file\n",
    "ewatercycle.CFG.save_to_file()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4f040610-48f7-4216-be3d-686b06e9c638",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter set\n",
      "-------------\n",
      "name=329_camels_06043500_3km\n",
      "directory=/gpfs/home6/jaerts/eWaterCycle_example_data/wflow_camels_parameters/3km/13_camels_01123000_3km\n",
      "config=/gpfs/home6/jaerts/eWaterCycle_example_data/wflow_camels_parameters/3km/13_camels_01123000_3km/wflow_sbm_calibration.ini\n",
      "doi=N/A\n",
      "target_model=wflow\n",
      "supported_model_versions={'2020.1.1', '2020.1.2'}\n"
     ]
    }
   ],
   "source": [
    "# Load parameter set\n",
    "parameter_set = ewatercycle.parameter_sets.get_parameter_set(\"329_camels_06043500_3km\")\n",
    "print(parameter_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "248eddb4-5fa5-49f4-aa79-2198cd3a14b6",
   "metadata": {},
   "source": [
    "# Forcing\n",
    "The model specific ERA5 forcing is generated using the extent of a shapefile."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9208aef0-72e2-4a81-a134-5cce08434b9c",
   "metadata": {},
   "source": [
    "## Extract basin shapefile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b66de3f0-3a7c-4757-9f55-d9d8d199eb4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read CAMELS shapefile\n",
    "gdf = gpd.read_file(\n",
    "    f\"{AUXDIR}/camels_basin_shapefiles/HCDN_nhru_final_671.shp\", index_col=\"hru_id\"\n",
    ")\n",
    "\n",
    "# Fix missing leading zero Basin ID\n",
    "index = gdf.hru_id.to_list()\n",
    "index = [str(x) for x in index]\n",
    "index = [\"0\" + x if len(x) == 7 else x for x in index]\n",
    "\n",
    "# Extract sub-shapefile\n",
    "gdf[\"basin_id\"] = index\n",
    "gdf = gdf.set_index(\"basin_id\")\n",
    "gdf = gdf.loc[basin_id]\n",
    "\n",
    "# Save single basin shapefile\n",
    "gpd.GeoDataFrame(geometry=[gdf.geometry]).to_file(f\"{BASINDIR}/staticgeoms/basin.shp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25eb3f71-7aaa-40e3-8909-47f9ad86b75c",
   "metadata": {},
   "source": [
    "## Create Forcing\n",
    "Here we generate the forcing for a specified time period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9054d95f-27af-494a-be47-061834079002",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "wflow_forcing = ewatercycle.forcing.generate(\n",
    "    target_model=\"wflow\",\n",
    "    dataset=\"ERA5\",\n",
    "    start_time=\"1996-01-01T00:00:00Z\",\n",
    "    end_time=\"2005-12-31T00:00:00Z\",\n",
    "    shape=f\"{BASINDIR}/staticgeoms/basin.shp\",\n",
    "    model_specific_options={\n",
    "        \"dem_file\": f\"{BASINDIR}/staticmaps/wflow_dem.map\",\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c76b8a-c15d-454e-9347-90fdf9f8075d",
   "metadata": {},
   "source": [
    "# Setting Up Model Run\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "511f2c42-aeb8-41d7-8ec4-8c3b5deefcc9",
   "metadata": {},
   "source": [
    "## Get Streamflow Observation Data\n",
    "First we download the USGS streamflow observation that is unit and timezone corrected. Next we retrieve the station location information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b524b00b-331a-455a-89ff-12c43df8a134",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download USGS streamflow data\n",
    "ds_obs = get_usgs_data(\n",
    "    basin_id,\n",
    "    \"1996-01-01\",\n",
    "    \"2005-12-31\",\n",
    "    cache_dir=\"/gpfs/home6/jaerts/example_notebook_ewatercycle/obs_data/\",\n",
    ")\n",
    "\n",
    "# Retrieve station latitude and longitude information\n",
    "station_lat, station_lon = ds_obs.attrs[\"location\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fadfc6c-def4-4232-8e80-04b4f7770ce7",
   "metadata": {},
   "source": [
    "## Specify Calibration Information\n",
    "We specify the calibration value interval which spawns model instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "589c4b2e-7da3-4508-87c3-6e07a2907f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify Manual Calibration KsatHorFrac Values (longer in Aerts et al.)\n",
    "calibration_interval = [1, 10, 25, 50, 75, 100, 250, 500, 1000]\n",
    "\n",
    "\n",
    "def set_calibration_parameter(model_instance_dir, parameter_value):\n",
    "    parameter_file = f\"{model_instance_dir}/intbl/KsatHorFrac.tbl\"\n",
    "    print(parameter_file)\n",
    "\n",
    "    with open(parameter_file) as tablefile:\n",
    "        table = tablefile.read()\n",
    "        table = table.replace(\"100\", parameter_value)\n",
    "        table_new = open(parameter_file, \"w\")\n",
    "\n",
    "        table_new.write(table)\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd116949-a26e-40f5-a7c5-675131775c78",
   "metadata": {},
   "source": [
    "## Create list for parallel model run"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e4c6cc1-6d05-4b40-9dd3-6c4cabb1c1dc",
   "metadata": {},
   "source": [
    "We pass lists to the function that runs the model on a single core to be implemented on multiple cores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "231203e2-6080-4e76-b49b-acefbd26dae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate lenght of lists\n",
    "list_length = len(calibration_interval)\n",
    "\n",
    "# Create lists\n",
    "basin_ids = list_length * [basin_id]\n",
    "resolutions = list_length * [resolution]\n",
    "station_lats = list_length * [station_lat]\n",
    "station_lons = list_length * [station_lon]\n",
    "cfg_dirs = []\n",
    "\n",
    "# Pass custom string to output directory creation\n",
    "for calibration_value in calibration_interval:\n",
    "    cfg_dir = f'{OUTDIR}/wflow_calibration_{basin_id}_{resolution}_ksathorfrac_{calibration_value}'\n",
    "    cfg_dirs.append(cfg_dir) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "007fcb68-993f-48aa-a7f9-c418dcc08702",
   "metadata": {},
   "source": [
    "# Parallel calibration run"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "209bca56-8783-4d6f-a227-7e3e11fd0a34",
   "metadata": {},
   "source": [
    "## Single core function "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e99086fa-66de-4729-85fe-deb4b5743d60",
   "metadata": {},
   "source": [
    "Here we set the function that runs the model for a single core as described in the first usecase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2159bfc0-ac0a-4d84-b876-a331b8e1f69c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_calibration_run(\n",
    "    basin_id,\n",
    "    resolution,\n",
    "    station_lat,\n",
    "    station_lon,\n",
    "    calibration_value,\n",
    "    cfg_dir\n",
    "):\n",
    "\n",
    "    # Specify model, model version, parameter set, forcing info\n",
    "    model = ewatercycle.models.Wflow(\n",
    "        version=\"2020.1.2\", parameter_set=parameter_set, forcing=wflow_forcing\n",
    "    )\n",
    "\n",
    "    # Setup the model    \n",
    "    config_file, config_dir = model.setup(cfg_dir)\n",
    "\n",
    "    # Set Calibration Parameter Values (KSatHorFrac)\n",
    "    set_calibration_parameter(config_dir, str(calibration_value))\n",
    "\n",
    "    # Initialize Model Instance\n",
    "    model.initialize(config_file)\n",
    "\n",
    "    # Create empty list for output storage\n",
    "    output_dict = {}\n",
    "    output_dict[f\"KsatHorFrac_{calibration_value}\"] = []\n",
    "\n",
    "    # Run Loop until model end time\n",
    "    while model.time < model.end_time:\n",
    "\n",
    "        # Advance model with single timestep\n",
    "        model.update()\n",
    "\n",
    "        # Retrieve simultated streamflow value at observation station location\n",
    "        output_dict[f\"KsatHorFrac_{calibration_value}\"].append(\n",
    "            model.get_value_at_coords(\n",
    "                \"RiverRunoff\", lon=[station_lon], lat=[station_lat]\n",
    "            )[0]\n",
    "        )\n",
    "\n",
    "        print(model.time_as_isostr, end=\"\\r\")\n",
    "\n",
    "    model.finalize()\n",
    "\n",
    "    return output_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e1a1fcf-c875-4ce4-a17e-4c29c24dec2f",
   "metadata": {},
   "source": [
    "# Start parallel run"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec7b2ee-779b-4121-992c-7428bde33c4b",
   "metadata": {},
   "source": [
    "Next we call the single core function using list that is deployed on multiple cores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "79811bbc-f5af-4f3d-820c-8488f8981238",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parallel_model_calibration(\n",
    "    basin_ids,\n",
    "    resolution,\n",
    "    station_lats,\n",
    "    station_lons,\n",
    "    calibration_interval,\n",
    "    cfg_dirs,\n",
    "    threads=None,\n",
    "):\n",
    "    # Set number of threads (cores) used for parallel run and map threads\n",
    "    if threads is None:\n",
    "        pool = Pool()\n",
    "    else:\n",
    "        pool = Pool(nodes=threads)\n",
    "    # Run parallel models\n",
    "    results = pool.map(\n",
    "        model_calibration_run,\n",
    "        basin_ids,\n",
    "        resolutions,\n",
    "        station_lats,\n",
    "        station_lons,\n",
    "        calibration_interval,\n",
    "        cfg_dirs,\n",
    "    )\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a21d9aa-5e18-4a86-82af-d0cd047be07e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:ewatercycle.models.wflow:Config file from parameter set is missing API section, adding section\n",
      "WARNING:ewatercycle.models.wflow:Config file from parameter set is missing RiverRunoff option in API section, added it with value '2, m/s option'\n",
      "WARNING:ewatercycle.models.wflow:Config file from parameter set is missing API section, adding section\n",
      "WARNING:ewatercycle.models.wflow:Config file from parameter set is missing RiverRunoff option in API section, added it with value '2, m/s option'\n",
      "WARNING:ewatercycle.models.wflow:Config file from parameter set is missing API section, adding section\n",
      "WARNING:ewatercycle.models.wflow:Config file from parameter set is missing RiverRunoff option in API section, added it with value '2, m/s option'\n",
      "WARNING:ewatercycle.models.wflow:Config file from parameter set is missing API section, adding section\n",
      "WARNING:ewatercycle.models.wflow:Config file from parameter set is missing RiverRunoff option in API section, added it with value '2, m/s option'\n",
      "WARNING:ewatercycle.models.wflow:Config file from parameter set is missing API section, adding section\n",
      "WARNING:ewatercycle.models.wflow:Config file from parameter set is missing RiverRunoff option in API section, added it with value '2, m/s option'\n",
      "WARNING:ewatercycle.models.wflow:Config file from parameter set is missing API section, adding section\n",
      "WARNING:ewatercycle.models.wflow:Config file from parameter set is missing RiverRunoff option in API section, added it with value '2, m/s option'\n",
      "WARNING:ewatercycle.models.wflow:Config file from parameter set is missing API section, adding section\n",
      "WARNING:ewatercycle.models.wflow:Config file from parameter set is missing RiverRunoff option in API section, added it with value '2, m/s option'\n",
      "WARNING:ewatercycle.models.wflow:Config file from parameter set is missing API section, adding section\n",
      "WARNING:ewatercycle.models.wflow:Config file from parameter set is missing RiverRunoff option in API section, added it with value '2, m/s option'\n",
      "WARNING:ewatercycle.models.wflow:Config file from parameter set is missing API section, adding section\n",
      "WARNING:ewatercycle.models.wflow:Config file from parameter set is missing RiverRunoff option in API section, added it with value '2, m/s option'\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "results = {}\n",
    "results = parallel_model_calibration(\n",
    "    basin_ids,\n",
    "    resolution,\n",
    "    station_lats,\n",
    "    station_lons,\n",
    "    calibration_interval,\n",
    "    cfg_dirs,\n",
    "    threads=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "775e4811-bd1a-450f-894e-7159c6df17ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b68a125-c8ba-42e8-b63b-e3d9c36c46ef",
   "metadata": {},
   "source": [
    "# Store Output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf6234aa-9d1e-4da0-96ca-fcac6de5124b",
   "metadata": {},
   "source": [
    "We start with defining the general output metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c99e7c-1be3-47b0-b2bd-884960acd7a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = {\n",
    "    \"description\": \"simulated streamflow\",\n",
    "    \"basin_id\": basin_id,\n",
    "    \"parameter_set-name\": parameter_set.name,\n",
    "    \"parameter_set-doi\": parameter_set.doi,\n",
    "    \"parameter_set-target_model\": parameter_set.target_model,\n",
    "    \"parameter_set-supported_model_versions\": (\n",
    "        list(parameter_set.supported_model_versions)[0],\n",
    "        list(parameter_set.supported_model_versions)[1],\n",
    "    ),\n",
    "    \"forcing-name\": wflow_forcing.netcdfinput,\n",
    "    \"forcing-recipe\": \"recipe_wflow.yml\",\n",
    "    \"forcing-diagnostic\": \"wflow.py\",\n",
    "    \"forcing-esmvaltool_version\": \"2.3.0\",\n",
    "    \"forcing-doi\": \"N/A\",\n",
    "    \"author\": \"Jerom Aerts\",\n",
    "    \"affiliation\": \"Delft University of Technology\",\n",
    "    \"contact\": \"j.p.m.aerts@tudelft.nl\",\n",
    "    \"creation date\": str(date.today()),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9407ab4c-6b8b-4cd9-baa9-3222ca4a4cd6",
   "metadata": {},
   "source": [
    "Next we store the simulated streamflow grid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c6c054-c854-4895-bef7-ec0bf98778f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_instance_output = []\n",
    "\n",
    "for key, model in models.items():\n",
    "    print(key)\n",
    "    # Concatenate xarray data arrays to dataset\n",
    "    da_grid = xr.concat(streamflow_grid[key], dim=\"time\")\n",
    "\n",
    "    # Rename the data variable\n",
    "    da_grid = da_grid.rename(f\"{key}_{resolution}_Q\")\n",
    "\n",
    "    # Add basin id as dimension\n",
    "    da_grid = da_grid.expand_dims(dim=\"basin_id\")\n",
    "    da_grid = da_grid.assign_coords({\"basin_id\": ([\"basin_id\"], [basin_id])})\n",
    "\n",
    "    # Add the metadata\n",
    "    for key_dict, item_dict in metadata.items():\n",
    "        da_grid.attrs[f\"{key_dict}\"] = item_dict\n",
    "\n",
    "    # Store individual instance output netcdf\n",
    "    da_grid.to_netcdf(f\"{OUTDIR}/{key}_{resolution}_streamflow_grid.nc\")\n",
    "\n",
    "    # Append to list\n",
    "    model_instance_output.append(da_grid)\n",
    "\n",
    "# Concatenate model_instances\n",
    "ds_grid = xr.merge(model_instance_output)\n",
    "ds_grid.to_netcdf(f\"{OUTDIR}/{basin_id}_{resolution}_parallel_calibration_streamflow_grid.nc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b47c19f-c62d-425d-b30f-d8ab20903363",
   "metadata": {},
   "source": [
    "### Check Output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "442c8d53-cc02-479a-86b5-30c92e912178",
   "metadata": {},
   "source": [
    "Lets check the output for a single model instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e5f79b-1b2a-4242-9f17-5f07c9cf96af",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot interactive plot\n",
    "ds_grid.KsatHorFrac_1_3km_Q.sel(basin_id=basin_id).hvplot(\n",
    "    groupby=\"time\",  # adds a widget for time\n",
    "    clim=(\n",
    "        ds_grid.KsatHorFrac_1_3km_Q.sel(basin_id=basin_id).min(),\n",
    "        ds_grid.KsatHorFrac_1_3km_Q.sel(basin_id=basin_id).max(),\n",
    "    ),\n",
    "    widget_location=\"bottom\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b063e1f4-54ca-4183-94c3-7bc37bd94e77",
   "metadata": {},
   "source": [
    "Next, we store the streamflow timeseries at the basin outlet/observation station location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd57a94-e49d-4aed-b3d4-b9537a7d939c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "datasets = []\n",
    "\n",
    "for key, model in streamflow_timeseries.items():\n",
    "\n",
    "    # Get timeseries data\n",
    "    series = streamflow_timeseries[key]\n",
    "\n",
    "    # Define data variable\n",
    "    data_vars = dict({f\"{key}_{resolution}_Q\": ([\"time\"], series)})\n",
    "\n",
    "    # define coordinates\n",
    "    coords = dict({\"time\": ([\"time\"], time)})\n",
    "\n",
    "    # Create data array\n",
    "    da_series = xr.Dataset(data_vars=data_vars, coords=coords)\n",
    "\n",
    "    # Add basin id as dimension\n",
    "    da_series = da_series.expand_dims(dim=\"basin_id\")\n",
    "    da_series = da_series.assign_coords({\"basin_id\": ([\"basin_id\"], [basin_id])})\n",
    "\n",
    "    # Add the metadata\n",
    "    for key_dict, item_dict in metadata.items():\n",
    "        da_series.attrs[f\"{key_dict}\"] = item_dict\n",
    "\n",
    "    # Add basin specific metadata\n",
    "    da_series.attrs[\"station_lat\"] = station_lat\n",
    "    da_series.attrs[\"station_lon\"] = station_lon\n",
    "\n",
    "    # Append to list\n",
    "    datasets.append(da_series)\n",
    "\n",
    "\n",
    "# datasets = xr.concat(datasets, dim='index')\n",
    "ds_series = xr.merge(datasets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a199ea3-a482-4a6e-a40a-64d6a5d94368",
   "metadata": {},
   "source": [
    "### Check Output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17324214-d8f3-4ae7-a7d2-982a89afc454",
   "metadata": {},
   "source": [
    "Lets check the output for a single model instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "040a68f5-d477-407e-8b6d-c7577f9818c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_series.KsatHorFrac_1_3km_Q.sel(basin_id=basin_id).hvplot(\n",
    "    widget_location=\"bottom\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "befc38af-bf2f-451f-84ba-d01e91ec2876",
   "metadata": {},
   "source": [
    "# Analyse Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36c35d93-b39b-418a-bce7-bda3f57c471a",
   "metadata": {},
   "source": [
    "First we need to resample the hourly USGS observation data to daily values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "515f7444-9483-4f49-b09b-2bc462d6810f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resample Hourly USGS Data to Daily Values\n",
    "ds_obs = ds_obs.resample(time=\"1D\").mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8522d9b1-381a-4102-a554-44463a59af99",
   "metadata": {},
   "source": [
    "A dataframe is constructed for use with the hydroerr package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c638dd4e-00e9-4a4d-a232-9f5c252a7779",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct dataframes\n",
    "df_obs = ds_obs.to_dataframe()\n",
    "df_sim = ds_series.to_dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95f40815-b483-4e2e-8361-80ebf6db0f17",
   "metadata": {},
   "source": [
    "## Calculate Objective Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9021730-2815-44b8-9e91-fe61ffa1849c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Objective Functions\n",
    "def calculate_objective_functions(\n",
    "    simulation_dataframe, observation_dataframe, resolution\n",
    "):\n",
    "    # Construct empty dataframe and lists for results\n",
    "    objective_function_dataframe = pd.DataFrame()\n",
    "\n",
    "    basin_ids = []\n",
    "    resolutions = []\n",
    "    model_instances = []\n",
    "    param_values = []\n",
    "\n",
    "    kge_values = []\n",
    "    nse_values = []\n",
    "\n",
    "    # Iterate output of model instances\n",
    "    for column in simulation_dataframe:\n",
    "        # Append run info to lists\n",
    "        basin_ids.append(simulation_dataframe.index[0][0])\n",
    "        resolutions.append(resolution)\n",
    "        model_instances.append(column)\n",
    "        param_values.append(column.split(\"_\")[1])\n",
    "\n",
    "        # Merge dataframes\n",
    "        df = simulation_dataframe[column].to_frame().join(observation_dataframe)\n",
    "\n",
    "        # Calculate objective functions\n",
    "        kge_values.append(he.kge_2012(df[column], df[\"streamflow\"].values))\n",
    "        nse_values.append(he.nse(df[column], df[\"streamflow\"].values))\n",
    "\n",
    "    # Construct output dataframe\n",
    "    objective_function_dataframe[\"basin_id\"] = basin_ids\n",
    "    objective_function_dataframe[\"resolution\"] = resolutions\n",
    "    objective_function_dataframe[\"model_instance\"] = model_instances\n",
    "    objective_function_dataframe[\"KsatHorFrac_value\"] = param_values\n",
    "    objective_function_dataframe[\"kge_value\"] = kge_values\n",
    "    objective_function_dataframe[\"nse_value\"] = nse_values\n",
    "\n",
    "    return objective_function_dataframe\n",
    "\n",
    "\n",
    "df_obj = calculate_objective_functions(df_sim, df_obs, \"3km\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "127b0d47-f1e9-43c2-a82c-320f93f80acf",
   "metadata": {},
   "source": [
    "# Plot hydrograph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f8658be-de90-48b7-8529-cdecc97c6095",
   "metadata": {},
   "source": [
    "Here we construct the hydrograph for visual inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f059bccb-2699-42e9-8ae9-f3c40c8c7ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(15, 10))\n",
    "\n",
    "params = {\n",
    "    \"legend.fontsize\": 30,\n",
    "    \"legend.handlelength\": 2,\n",
    "    \"xtick.labelsize\": 30,\n",
    "    \"ytick.labelsize\": 30,\n",
    "}\n",
    "\n",
    "# sns.lineplot(ax=ax, x=df.index, y=df['KsatHorFrac_100'],  data=df, label=key, alpha=0.8)\n",
    "\n",
    "# Plot Streamflow observations\n",
    "sns.lineplot(\n",
    "    ax=ax,\n",
    "    x=df_obs.index,\n",
    "    y=df_obs.streamflow,\n",
    "    data=df_obs,\n",
    "    linewidth=3.5,\n",
    "    color=\"tab:red\",\n",
    "    label=\"Observations\",\n",
    "    alpha=0.8,\n",
    ")\n",
    "\n",
    "# Plot Calibration Interval\n",
    "df_sim.index = df_sim.index.droplevel()\n",
    "for column in df_sim:\n",
    "    sns.lineplot(\n",
    "        ax=ax,\n",
    "        x=df_sim.index,\n",
    "        y=df_sim[column].values,\n",
    "        data=df_sim,\n",
    "        label=column,\n",
    "        alpha=0.8,\n",
    "        linewidth=2.5,\n",
    "    )\n",
    "\n",
    "# Plot objective function results table\n",
    "df = df_obj.drop(columns=\"model_instance\")\n",
    "df = df.round(2)\n",
    "table = plt.table(\n",
    "    cellText=df.values,\n",
    "    rowLabels=None,\n",
    "    colLabels=df.columns,\n",
    "    bbox=(-0.001, -0.2, 1, 0.1),\n",
    ")\n",
    "table.auto_set_font_size(False)\n",
    "table.set_fontsize(12)\n",
    "\n",
    "\n",
    "# Set axis and Title\n",
    "ax.set_xlabel(\"Date\", size=20)\n",
    "ax.set_ylabel(\"Q (m3*s-1)\", fontsize=20)\n",
    "ax.set_title(f\"Basin ID:{basin_id} - Resolution:{resolution}\", size=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e797f53e-56b1-4e31-8e33-3b077860a2c5",
   "metadata": {},
   "source": [
    "# Select best calibration Parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b5e7546-1755-478d-a7bf-43dcc063e246",
   "metadata": {},
   "source": [
    "Now we select and set the best KsatHorFrac parameter based on the KGE objective score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fa1d5d88-e09b-46f3-9671-072eba543c90",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_obj' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/scratch-local/jaerts.126346/ipykernel_2557077/1966655128.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Sort the objective function results dataframe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf_obj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mby\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"kge_value\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mascending\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Select the ksathorfrac parameter with the highest KGE score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mksathorfrac_param\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mKsatHorFrac_value\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_obj' is not defined"
     ]
    }
   ],
   "source": [
    "# Sort the objective function results dataframe\n",
    "df_obj = df_obj.sort_values(by=\"kge_value\", ascending=False)\n",
    "\n",
    "# Select the ksathorfrac parameter with the highest KGE score\n",
    "ksathorfrac_param = df_obj.KsatHorFrac_value.values[0]\n",
    "\n",
    "# Set the parameter value in the parameter set\n",
    "set_calibration_parameter(BASINDIR, ksathorfrac_param)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f5d691e-3c7b-484a-bb71-e11c7e4ca9a7",
   "metadata": {},
   "source": [
    "# Thank you for viewing!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "122ff1a8-89fa-4444-b0a8-a4ae8fcfa444",
   "metadata": {},
   "source": [
    "### Interested in using eWaterCycle, checkout the package https://ewatercycle.readthedocs.io/en/latest/ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a87e21b8-3a11-4ebc-a329-a2684665ecae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
